# -*- coding: utf-8 -*-
"""Untitled8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WAHhKxBn8Mp2LNY_nsnJyE2f78Mwh5kM
"""

import urllib
import urllib.request 
from bs4 import BeautifulSoup as bs 
import time ;

#Making a function to extract the soup data from the url 
def make_soup(url):
    thepage  = urllib.request.urlopen(url)
    soupdata = bs(thepage ,"html.parser")
    return soupdata

#Now , going to the url and extracting the desired table.
link_with_text = {}
i = 1 
while( i <=51):
  print(i)
  if(i == 1):
    page1 = make_soup("http://stats.espncricinfo.com/ci/engine/stats/index.html?class=2;template=results;type=batting")
    table_page1 = page1.find_all('table',{"class":"engineTable" })
    table_page1 = table_page1[2]
  else:
    link = "http://stats.espncricinfo.com/ci/engine/stats/index.html?class=2;page=1;template=results;type=batting"
    new_str = 'page=' + str(i)
    link = link.replace('page=1' ,new_str)
    page1 = make_soup(link)
    table_page1 = page1.find_all('table',{"class":"engineTable" })
    table_page1 = table_page1[2]
#Extracting the only table present in that class , Now it's time to get the name of players 
#and link to next page where it contains players year wise performance.
  for row in table_page1.findAll('td'):
    for cell in row.findAll('a' , href = True):
      if(cell['href'].startswith('/ci/content/player')):
        cell['href'] = cell['href'].replace('/ci/content','http://stats.espncricinfo.com/ci/engine')
        cell['href'] = cell['href'] + '?class=2;template=results;type=batting;view=innings'
        link_with_text[row.text] = cell['href']
  i=i+1
len(link_with_text)

link_with_text

#Cross Check
link_with_text['Zakir Hasan (BDESH)']

#Yes , we got the right links.We shall retreive the soup's from all the links and now 
#store it in a list.
import requests 
soup_list = []
j = 0 
for i in link_with_text.values():
    response = requests.get(i)
    if(response.status_code == 200):
      print(j,list(link_with_text)[j])
      soup_list.append(make_soup(i))
    else : 
      print("NO RESPONSE -",list(link_with_text)[j])
    j = j+1

soup_bat = []
for i in soup_list : 
  table_need = i.find_all('table',{"class":"engineTable"})
  table_need = table_need[3]  # In that site , there are so many tables . Choosing the right table that we need.
  soup_bat.append(table_need)

len(soup_bat)

## Removing the duplicate values.
def Remove(duplicate): 
    final_list = [] 
    for num in duplicate: 
        if num not in final_list: 
            final_list.append(num) 
    return final_list

from collections import Counter
#Making the required soup (particular rows and columns)
final_soup_list = []
count = 0
for i in range(len(soup_bat)):
  
  first_list = []
  for row in soup_bat[i].find_all('tr'):
    first_col = row.find_all('td')
    first_list.append(first_col)
  final_soup_list.append(first_list)

  
# Iterating to All runs the scored by each player.
final_full_runs = []
final_full_years = []
for j in range(len(final_soup_list)):
  count = count + 1 
  full_runs = []
  full_year  = []
  each = final_soup_list[j]
  for i in range(1,len(each)):
    runs = each[i][0].text
    runs = runs.replace('TDNB','0')
    runs = runs.replace('DNB','0') ##### Cleaning all the data which contains 'TDNB' , 'DNB' ,'Absent' as zero
    runs = runs.replace('*','')
    runs = runs.replace('absent','0')
    runs = runs.replace('sub' ,'0')
    runs_int = int(runs)
    date = each[i][12].text
    year = int(date[-4:])
    full_runs.append(runs_int)
    full_year.append(year)
  a = dict(Counter(full_year))
  i = 0
  final_runs = []
  year = full_year[0]
  #print(count,year)
  while i <len(full_runs):
    sum = 0 
    if year not in full_year:
      year = year + 1
    else:
      for j in range(a[year]):
        sum = sum + full_runs[i]   ##Adding all the runs he had scored in that particular Year.
        i = i +1 
      final_runs.append(sum)
      year = year + 1 
  final_year = Remove(full_year)
  #print(final_year)
  #print(final_runs)
  final_full_runs.append(final_runs)  #Finally appending all player runs in each year to a single list ( list of lists)
  final_full_years.append(final_year) #Contains every year that a particular player has played(list of lists) 
len(final_full_runs)

import pandas as pd
import numpy as np
# Intialisation of dataframe with 1st player 
full = [final_full_years[0],final_full_runs[0]]
full = np.array(full)
df_main = pd.DataFrame(data = full,index = [0,1])
df_main.columns = df_main.iloc[0]    #Setting Years as Columns
df_main = df_main.reindex(df_main.index.drop(0))

#Appending all players data to the main data frame 
for j in range(1,len(final_full_runs)):
    full = [final_full_years[j],final_full_runs[j]]
    full = np.array(full)
    df = pd.DataFrame(data = full,index = [0 , j+1]) #while appending each player to dataframeincreasin the index value 
    df.columns = df.iloc[0] #Setting Years as Columns 
    df = df.reindex(df.index.drop(0))
    df_main = df_main.append(df, sort = True)
df_main =df_main.fillna(value=0) #Replacing NaN with value 0 
df_main

#Now , cumulative the runs
for i in df_main.columns: 
    if(i == list(df_main.columns)[0]):
        pass 
    else:
        df_main[i] = df_main[i]+df_main[i-1]
df_main # Done , with the data .

#Separating the players name and their nationality 
playernames = list(link_with_text.keys())
final_name = []
nationality = []
for i in playernames : 
  bro = i.split('(')
  final_name.append(bro[0].strip())
  nationality.append(bro[1][:-1])

name = ['Player'] +final_name
nationality = ['Country'] + nationality
nationality



names = np.array(name)
name_s = pd.Series(data = names)
nationality = np.array(nationality)
nationality_s =pd.Series(nationality)
df_new = pd.concat([name_s , nationality_s] , axis = 1 )
df_new.columns = df_new.iloc[0]
df_new = df_new.reindex(df_new.index.drop(0))
type(df_new)

#Finally , Now we have to merge this final data with intial data frame which contains 
#Players Name and  his Nationality.
df_final = pd.concat([df_new , df_main] , axis = 1 )
df_final

df_final.to_csv('TotalRunsByPlayersinODI' , index = False)